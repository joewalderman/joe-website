[
  {
    "path": "posts/2021-03-15-parameter-estimation-for-wild-fish-catch/",
    "title": "Parameter Estimation for Wild Fish Catch",
    "description": "Nonlinear least squares analysis of global wild fish catch",
    "author": [
      {
        "name": "Joe Walderman",
        "url": {}
      }
    ],
    "date": "2021-03-05",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nOverview\r\nExploration of the Data: Time Series and Parameter Estimation\r\nNonlinear Least Squares for Parameter Estimation\r\nPrediction Visualization\r\nCitation:\r\n\r\n\r\nhide\r\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\r\nlibrary(tidyverse)\r\nlibrary(here)\r\nlibrary(janitor)\r\nlibrary(boot) # for bootstrapping\r\nlibrary(gt) # table formatting\r\nlibrary(nlstools) # nonlinear least squares fit\r\nlibrary(broom)\r\n\r\n\r\n\r\nOverview\r\nIn this analysis we will use nonlinear least squares to look at wild fish catch data from 1950-2012 generated by the Earth Policy Institute.\r\nExploration of the Data: Time Series and Parameter Estimation\r\n\r\nhide\r\n# Reading in and wrangling the data\r\nfish <- read_csv(here(\"fishcatch\", \"fish_catch.csv\"), skip = 2) %>% \r\n  drop_na() %>% \r\n  clean_names() %>% \r\n  mutate(year = as.numeric(year)) %>% \r\n  mutate(wild_catch = as.numeric(wild_catch)) %>% \r\n  mutate(year_number = 0:62)\r\n\r\n# Fish catch time series plot\r\nggplot(data = fish, aes(x = year, y = wild_catch)) +\r\n  geom_line() +\r\n  scale_y_continuous(breaks = c(10,20,30,40,50,60,70,80,90,100)) +\r\n  labs(x = \"Year\",\r\n       y = \"Fish (Million Tons)\",\r\n       title = \"Wild Fish Caught 1950-2012\") +\r\n  theme_minimal()\r\n\r\n\r\nhide\r\nfish_exp <- fish %>% \r\n  filter(year < 1990) %>% \r\n  mutate(ln_wild = log(wild_catch))\r\n\r\n# Linear model to get k estimate\r\nlm_k <- lm(ln_wild ~ year_number, data = fish_exp)\r\nlm_tidy <- tidy(lm_k)\r\n\r\n\r\n\r\nThis exploratory graph shows a generally increasing trend of wild fish catch over time. The growth pattern seems to be one of logistic growth, exhibited by initial exponential growth eventually leveling off at a carrying capacity. This growth can be described mathematically as:\r\n\\(P(t) = \\frac{K}{1+Ae^{-kt}}\\)\r\nK Estimate: Around 1990 fish catch seems to level off at around 90-95 million tons per year. Thus the estimate for carrying capacity K is 95 million tons.\r\nA Estimate: The population at 1950, time zero in this case, is ~18 milion tons. Thus A ~ \\(\\frac{95-18}{18}\\) ~ 4.3\r\nk Estimate: k is estimated by looking at log of wild fish before 1990 to get the growth rate. It is estimated to be k = ~0.04.\r\nNonlinear Least Squares for Parameter Estimation\r\n\r\nhide\r\n# NLS Model\r\nfish_nls <- nls(wild_catch ~ K/(1 + A*exp(-r*year_number)),\r\n                data = fish,\r\n                start = list(K = 95,\r\n                             A = 4.3,\r\n                             r = 0.04),\r\n                trace = TRUE)\r\n\r\n# Model summary\r\n#summary(fish_nls)\r\n\r\n# Tidy output\r\nfish_output <- tidy(fish_nls)\r\n\r\n\r\n\r\n\r\nhide\r\n# Results Table\r\nfish_output %>% \r\n  mutate(p.value = case_when(\r\n    p.value < 0.0001 ~ \"<0.0001\"\r\n  )) %>% \r\n  gt() %>% \r\n  tab_header(\r\n    title = \"Nonlinear Least Squares Output\"\r\n  ) %>% \r\n  fmt_number(columns = vars(estimate, std.error, statistic),\r\n             decimals = 2\r\n  ) %>% \r\n  cols_label(\r\n    term = \"Term\",\r\n    estimate = \"Estimate\",\r\n    std.error = \"Standard Error\",\r\n    statistic = \"Statistic\",\r\n    p.value = \"P-Value\"\r\n  )\r\n\r\n\r\nhtml {\r\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\r\n}\r\n\r\n#baojckutxy .gt_table {\r\n  display: table;\r\n  border-collapse: collapse;\r\n  margin-left: auto;\r\n  margin-right: auto;\r\n  color: #333333;\r\n  font-size: 16px;\r\n  font-weight: normal;\r\n  font-style: normal;\r\n  background-color: #FFFFFF;\r\n  width: auto;\r\n  border-top-style: solid;\r\n  border-top-width: 2px;\r\n  border-top-color: #A8A8A8;\r\n  border-right-style: none;\r\n  border-right-width: 2px;\r\n  border-right-color: #D3D3D3;\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #A8A8A8;\r\n  border-left-style: none;\r\n  border-left-width: 2px;\r\n  border-left-color: #D3D3D3;\r\n}\r\n\r\n#baojckutxy .gt_heading {\r\n  background-color: #FFFFFF;\r\n  text-align: center;\r\n  border-bottom-color: #FFFFFF;\r\n  border-left-style: none;\r\n  border-left-width: 1px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 1px;\r\n  border-right-color: #D3D3D3;\r\n}\r\n\r\n#baojckutxy .gt_title {\r\n  color: #333333;\r\n  font-size: 125%;\r\n  font-weight: initial;\r\n  padding-top: 4px;\r\n  padding-bottom: 4px;\r\n  border-bottom-color: #FFFFFF;\r\n  border-bottom-width: 0;\r\n}\r\n\r\n#baojckutxy .gt_subtitle {\r\n  color: #333333;\r\n  font-size: 85%;\r\n  font-weight: initial;\r\n  padding-top: 0;\r\n  padding-bottom: 4px;\r\n  border-top-color: #FFFFFF;\r\n  border-top-width: 0;\r\n}\r\n\r\n#baojckutxy .gt_bottom_border {\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n}\r\n\r\n#baojckutxy .gt_col_headings {\r\n  border-top-style: solid;\r\n  border-top-width: 2px;\r\n  border-top-color: #D3D3D3;\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n  border-left-style: none;\r\n  border-left-width: 1px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 1px;\r\n  border-right-color: #D3D3D3;\r\n}\r\n\r\n#baojckutxy .gt_col_heading {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  font-size: 100%;\r\n  font-weight: normal;\r\n  text-transform: inherit;\r\n  border-left-style: none;\r\n  border-left-width: 1px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 1px;\r\n  border-right-color: #D3D3D3;\r\n  vertical-align: bottom;\r\n  padding-top: 5px;\r\n  padding-bottom: 6px;\r\n  padding-left: 5px;\r\n  padding-right: 5px;\r\n  overflow-x: hidden;\r\n}\r\n\r\n#baojckutxy .gt_column_spanner_outer {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  font-size: 100%;\r\n  font-weight: normal;\r\n  text-transform: inherit;\r\n  padding-top: 0;\r\n  padding-bottom: 0;\r\n  padding-left: 4px;\r\n  padding-right: 4px;\r\n}\r\n\r\n#baojckutxy .gt_column_spanner_outer:first-child {\r\n  padding-left: 0;\r\n}\r\n\r\n#baojckutxy .gt_column_spanner_outer:last-child {\r\n  padding-right: 0;\r\n}\r\n\r\n#baojckutxy .gt_column_spanner {\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n  vertical-align: bottom;\r\n  padding-top: 5px;\r\n  padding-bottom: 6px;\r\n  overflow-x: hidden;\r\n  display: inline-block;\r\n  width: 100%;\r\n}\r\n\r\n#baojckutxy .gt_group_heading {\r\n  padding: 8px;\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  font-size: 100%;\r\n  font-weight: initial;\r\n  text-transform: inherit;\r\n  border-top-style: solid;\r\n  border-top-width: 2px;\r\n  border-top-color: #D3D3D3;\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n  border-left-style: none;\r\n  border-left-width: 1px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 1px;\r\n  border-right-color: #D3D3D3;\r\n  vertical-align: middle;\r\n}\r\n\r\n#baojckutxy .gt_empty_group_heading {\r\n  padding: 0.5px;\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  font-size: 100%;\r\n  font-weight: initial;\r\n  border-top-style: solid;\r\n  border-top-width: 2px;\r\n  border-top-color: #D3D3D3;\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n  vertical-align: middle;\r\n}\r\n\r\n#baojckutxy .gt_from_md > :first-child {\r\n  margin-top: 0;\r\n}\r\n\r\n#baojckutxy .gt_from_md > :last-child {\r\n  margin-bottom: 0;\r\n}\r\n\r\n#baojckutxy .gt_row {\r\n  padding-top: 8px;\r\n  padding-bottom: 8px;\r\n  padding-left: 5px;\r\n  padding-right: 5px;\r\n  margin: 10px;\r\n  border-top-style: solid;\r\n  border-top-width: 1px;\r\n  border-top-color: #D3D3D3;\r\n  border-left-style: none;\r\n  border-left-width: 1px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 1px;\r\n  border-right-color: #D3D3D3;\r\n  vertical-align: middle;\r\n  overflow-x: hidden;\r\n}\r\n\r\n#baojckutxy .gt_stub {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  font-size: 100%;\r\n  font-weight: initial;\r\n  text-transform: inherit;\r\n  border-right-style: solid;\r\n  border-right-width: 2px;\r\n  border-right-color: #D3D3D3;\r\n  padding-left: 12px;\r\n}\r\n\r\n#baojckutxy .gt_summary_row {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  text-transform: inherit;\r\n  padding-top: 8px;\r\n  padding-bottom: 8px;\r\n  padding-left: 5px;\r\n  padding-right: 5px;\r\n}\r\n\r\n#baojckutxy .gt_first_summary_row {\r\n  padding-top: 8px;\r\n  padding-bottom: 8px;\r\n  padding-left: 5px;\r\n  padding-right: 5px;\r\n  border-top-style: solid;\r\n  border-top-width: 2px;\r\n  border-top-color: #D3D3D3;\r\n}\r\n\r\n#baojckutxy .gt_grand_summary_row {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  text-transform: inherit;\r\n  padding-top: 8px;\r\n  padding-bottom: 8px;\r\n  padding-left: 5px;\r\n  padding-right: 5px;\r\n}\r\n\r\n#baojckutxy .gt_first_grand_summary_row {\r\n  padding-top: 8px;\r\n  padding-bottom: 8px;\r\n  padding-left: 5px;\r\n  padding-right: 5px;\r\n  border-top-style: double;\r\n  border-top-width: 6px;\r\n  border-top-color: #D3D3D3;\r\n}\r\n\r\n#baojckutxy .gt_striped {\r\n  background-color: rgba(128, 128, 128, 0.05);\r\n}\r\n\r\n#baojckutxy .gt_table_body {\r\n  border-top-style: solid;\r\n  border-top-width: 2px;\r\n  border-top-color: #D3D3D3;\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n}\r\n\r\n#baojckutxy .gt_footnotes {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  border-bottom-style: none;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n  border-left-style: none;\r\n  border-left-width: 2px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 2px;\r\n  border-right-color: #D3D3D3;\r\n}\r\n\r\n#baojckutxy .gt_footnote {\r\n  margin: 0px;\r\n  font-size: 90%;\r\n  padding: 4px;\r\n}\r\n\r\n#baojckutxy .gt_sourcenotes {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  border-bottom-style: none;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n  border-left-style: none;\r\n  border-left-width: 2px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 2px;\r\n  border-right-color: #D3D3D3;\r\n}\r\n\r\n#baojckutxy .gt_sourcenote {\r\n  font-size: 90%;\r\n  padding: 4px;\r\n}\r\n\r\n#baojckutxy .gt_left {\r\n  text-align: left;\r\n}\r\n\r\n#baojckutxy .gt_center {\r\n  text-align: center;\r\n}\r\n\r\n#baojckutxy .gt_right {\r\n  text-align: right;\r\n  font-variant-numeric: tabular-nums;\r\n}\r\n\r\n#baojckutxy .gt_font_normal {\r\n  font-weight: normal;\r\n}\r\n\r\n#baojckutxy .gt_font_bold {\r\n  font-weight: bold;\r\n}\r\n\r\n#baojckutxy .gt_font_italic {\r\n  font-style: italic;\r\n}\r\n\r\n#baojckutxy .gt_super {\r\n  font-size: 65%;\r\n}\r\n\r\n#baojckutxy .gt_footnote_marks {\r\n  font-style: italic;\r\n  font-size: 65%;\r\n}\r\nNonlinear Least Squares Output\r\n    \r\n    Term\r\n      Estimate\r\n      Standard Error\r\n      Statistic\r\n      P-Value\r\n    K\r\n      100.28\r\n      2.73\r\n      36.68\r\n      <0.0001\r\n    A\r\n      4.32\r\n      0.29\r\n      14.73\r\n      <0.0001\r\n    r\r\n      0.07\r\n      0.00\r\n      15.04\r\n      <0.0001\r\n    \r\n\r\n\r\nFor these values the model is expressed as:\r\n\\(P(t) = \\frac{100.28}{1+4.32e^{0.07t}}\\)\r\nPrediction Visualization\r\n\r\nhide\r\n# Predictions\r\nfish_predict <- predict(fish_nls)\r\n\r\n# Combine the data frames into a single plot\r\nfish_complete <- data.frame(fish, fish_predict)\r\n\r\n# Plotting\r\nggplot(data = fish_complete, aes(x = year, y = wild_catch)) +\r\n  geom_point() +\r\n  geom_line(aes(y = fish_predict), color = \"orangered3\") +\r\n  theme_minimal() +\r\n  labs(x = \"Year\",\r\n       y = \" Wild Fish Caught (Million Tons)\",\r\n       title = \"Annual Wild Fish Catch from 1950-2012\")\r\n\r\n\r\n\r\n\r\nCitation:\r\nGlobal wild fish catch and aquaculture production, compiled by Earth Policy Institute with 1950-2010 from U.N. Food and Agriculture Organization (FAO), Global Capture Production and Global Aquaculture Production, electronic databases, at www.fao.org/fishery/topic/16140/en.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-15-parameter-estimation-for-wild-fish-catch/parameter-estimation-for-wild-fish-catch_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-03-15T18:14:36-07:00",
    "input_file": "parameter-estimation-for-wild-fish-catch.utf8.md"
  },
  {
    "path": "posts/2021-02-25-catch-22-text-analysis/",
    "title": "Text Analysis of Joseph Heller's Catch-22",
    "description": "Utilizing a variety of text wrangling packages and techniques, we will analyze word usage frequency and sentiments from Joseph Heller's *Catch-22*.",
    "author": [
      {
        "name": "Joe Walderman",
        "url": {}
      }
    ],
    "date": "2021-02-25",
    "categories": [],
    "contents": "\r\n\r\n“There was no telling what people might find out once they felt free to ask whatever questions they wanted to.”\r\n\r\nCatch-22 Text Wrangling\r\nSplit up the text by line and trim excess white space\r\n\r\nShow code\r\n# Reading in book pdf\r\ncatch22 <- pdf_text(here(\"_posts\", \"2021-02-25-catch-22-text-analysis\", \"data\", \"Catch-22.pdf\"))\r\n\r\n# Tidy data frame\r\ncatch22_tidy <- data.frame(catch22) %>% \r\n  mutate(text_full = str_split(catch22, pattern = \"\\\\n\")) %>% \r\n  unnest(text_full) %>% #making each line its own observation\r\n  mutate(text_full = str_trim(text_full))\r\n\r\ncatch22_df <- catch22_tidy %>% \r\n  slice(-(1:54)) %>% #getting rid of preface and table of contents\r\n  mutate(chapter = case_when(\r\n    str_detect(text_full, pattern = \"CHAPTER\") ~ text_full,\r\n               TRUE ~ NA_character_\r\n  )) %>% \r\n  fill(chapter) %>% \r\n  separate(col = chapter, into = c(\"chap\", \"title\"), sep = \" - \", extra = \"merge\") %>% \r\n  separate(col = chap, into = c(\"ch\", \"no\"), sep = \" \") %>% \r\n  mutate(chapter = as.numeric(no))\r\n\r\n\r\n\r\nGet word counts by chapter.\r\n\r\nShow code\r\n#getting tokens\r\ncatch22_tokens <- catch22_df %>% \r\n  unnest_tokens(word, text_full) %>% \r\n  select(-catch22)\r\n\r\n#wordcount by chapter\r\ncatch22_count <- catch22_tokens %>% \r\n  count(chapter, word)\r\n\r\n\r\n\r\nRemove common stop words such as “it”, “the”, and “a”.\r\n\r\nShow code\r\n#stopword removal\r\ncatch22_nonstop <- catch22_tokens %>% \r\n  anti_join(stop_words)\r\n\r\n#wordcount without stopwords\r\nnonstop_counts <- catch22_nonstop %>% \r\n  count(chapter, word)\r\n\r\n\r\n\r\nFinally, remove common names and titles for a more interesting picture of word usage by chapter.\r\n\r\nShow code\r\nnames <- c(\"yossarian\", \"yossarian's\", \"milo\", \"clevinger\", \"cathcart\", \"lieutenant\", \"captain\", \"colonel\", \"daneeka\", \"joe\", \"havermeyer\", \"cargill\", \"aarfy\", \"dreedle\", \"whitcomb\", \"danby\", \"scheisskopf\", \"nately\", \"orr\", \"peckem\", \"dunbar\", \"dreedle\", \"havermeyer\", \"mcwatt\", \"scheisskopf's\", \"corporal\", \"milo's\", \"korn\", \"korn's\", \"ferredge\", \"cramer\", \"cramer's\", \"ewing\", \"ewing's\", \"duckett\", \"pazzo\", \"snowden\", \"giuseppe\", \"sanderson\", \"moodus\", \"irving's\", \"dobbs\", \"sergeant\", \"coverley\", \"cathcart's\", \"aarfy's\", \"oran\", \"sampson\", \"fortiori\", \"wes\", \"danby's\", \"dreedle's\", \"whitcomb's\", \"colonel's\", \"appleby\", \"major\", \"lieutenant's\", \"nately's\", \"chaplain\", \"chaplain's\", \"washington\", \"metcalf\", \"metcalf's\", \"halfoat\", \"halfoat's\")\r\n\r\nnames_df <- as.data.frame(names) %>% \r\n  rename(word = names)\r\n\r\nno_names <- catch22_nonstop %>% \r\n  anti_join(names_df)\r\n\r\ncounts_no_names <- no_names %>% \r\n  count(chapter, word)\r\n\r\n\r\n\r\nVisualize the Results\r\n1) Top 5 words in Catch-22 part 2\r\n\r\nShow code\r\n#Find the top 5 words for part 2\r\n\r\ntop5_part2 <- counts_no_names %>% \r\n  filter(chapter %in% c(15:28)) %>% \r\n  group_by(chapter) %>% \r\n  arrange(-n) %>% \r\n  slice(1:5)\r\n\r\n#Making a visualization\r\nggplot(data = top5_part2, aes(x = word, y = n)) +\r\n  geom_col(fill = \"maroon\") +\r\n  facet_wrap(~chapter, scales = \"free\") +\r\n  coord_flip() +\r\n  theme_minimal() +\r\n  theme(text = element_text(size = 8),\r\n        plot.title = element_text(hjust = .6, size = 13)) +\r\n  labs(x = \"Word\",\r\n       y = \"Count\")\r\n\r\n\r\n\r\n\r\nFigure 1: Column graphs faceted by chapter to display top 5 most commonly used words in Joseph Heller’s Catch-22 part 2 (chapters 15-28). Stop words such as “it”, “us”, and “a” were removed in addition to character names and titles.\r\n2) Top 50 Words in Catch-22 Chapter 9: “Major Major Major Major”\r\n\r\nShow code\r\n#Getting top 50 words from chapter 9\r\nch9_top50 <- nonstop_counts %>% \r\n  filter(chapter == 9) %>% \r\n  arrange(-n) %>% \r\n  slice(1:50)\r\n\r\n#Reading in background image\r\ncatch <- jpeg::readJPEG(here(\"_posts\", \"2021-02-25-catch-22-text-analysis\", \"data\", \"catch-221.jpg\"))\r\n\r\n#Creating wordcloud\r\nch9_cloud <- ggplot(data = ch9_top50, aes(label = word)) +\r\n  background_image(catch) +\r\n  geom_text_wordcloud(aes(color = n, size = n), shape = \"triangle-forward\") +\r\n  scale_color_gradientn(colors = c(\"orange\", \"orange2\", \"orangered2\"))  +\r\n  scale_size_area(max_size = 23) +\r\n  theme_minimal()\r\n\r\n#Calling in output\r\nch9_cloud\r\n\r\n\r\n\r\n\r\nFigure 2: Wordcloud displaying the top 50 words used in Catch-22 chapter 9: “Major Major Major Major”. Stop words were removed but character names were left intact to show the impact of a character named Major Major Major Major.\r\nConduct Sentiment Analysis\r\nWe will conduct a sentiment analysis of Catch-22, looking at whether the words use in chapters of the book have positive or negative connotation in accordance with numerical ratings assigned by the AFINN lexicon. Given the book’s themes of war and absurdity and heavy usage of dark humor the expectation is a fairly consistent negative sentiment throughout the book\r\n3) Sentiment Analysis of Catch-22 using AFINN lexicon\r\n\r\nShow code\r\ncatch22_afinn <- catch22_nonstop %>% \r\n  inner_join(get_sentiments(\"afinn\"))\r\n\r\nafinn_counts <- catch22_afinn %>% \r\n  count(chapter, value)\r\n\r\nafinn_means <- catch22_afinn %>% \r\n  group_by(chapter) %>% \r\n  summarize(mean_afinn = mean(value))\r\n\r\nggplot(data = afinn_means,\r\n       aes(x = chapter, y = mean_afinn)) +\r\n  geom_col(fill = \"goldenrod\") +\r\n  coord_flip() +\r\n  theme_minimal() +\r\n  labs(x = \"Chapter\",\r\n       y = \"Mean Sentiment\")\r\n\r\n\r\n\r\n\r\nFigure 3: Column graph showcasing the average sentiments of Catch-22 using the AFINN lexicon. Mean sentiment values less than zero indicate that on average, the words used in a particular chapter had more negative connotations than those with mean sentiments greater than zero.\r\nCitation:\r\nHeller, Joseph, 1798-1849. Catch-22, a Novel. New York :The Modern library, 1961.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-02-25-catch-22-text-analysis/catch-22-text-analysis_files/figure-html5/unnamed-chunk-5-1.png",
    "last_modified": "2021-02-25T19:56:13-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-15-thailand-worst-plastic-polluters/",
    "title": "Thailand Worst Plastic Polluters",
    "description": "Companies contributing to the greatest portions of plastic polution in Thailand.",
    "author": [
      {
        "name": "Joe Walderman",
        "url": {}
      }
    ],
    "date": "2021-02-21",
    "categories": [],
    "contents": "\r\n#breakfreefromplastic is a global movement with support from over 12,000 organizations and individuals around the world. The goal of the movement is to reduce single-use plastics and work towrds solutions for the plastic pollution crisis.\r\n\r\nIn 2020, a collection of 905 volunteers collected 38,580 pieces of plastic from 115 companies in Thailand.\r\n\r\nhide\r\nplastics <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-01-26/plastics.csv')\r\n\r\n\r\n\r\n\r\n##use data for pet,pp and ps type plastics only\r\n\r\n# Replace null with unbranded\r\nplastics_clean <- plastics %>%\r\n  # Replace null with Unbranded in Parent Company\r\n  mutate(parent_company = ifelse(tolower(parent_company) == 'null', \r\n                                 'Unbranded', \r\n                                 parent_company)) %>%\r\n  # Remove Grand Total in Parent Company\r\n  filter(!(tolower(parent_company) == \"grand total\")) %>%\r\n  # Standardize Nestlé vs Nestle\r\n  mutate(parent_company = ifelse(parent_company == 'Nestle',\r\n                                 'Nestlé',\r\n                                 parent_company)) %>%\r\n  # Make long by plastic type\r\n  pivot_longer(empty:grand_total, \r\n               names_to = 'plastic_type', \r\n               values_to = 'count',\r\n               values_drop_na = TRUE) %>%\r\n  # Remove 0 counts\r\n  filter(count != 0)\r\n\r\n\r\nplastics_philippines <- \r\n  plastics %>% \r\n  filter(year == 2020, !parent_company %in% c(\"Unbranded\", \"NULL\", \"null\"), country == \"Thailand\") %>%    \r\n  mutate(parent_company = case_when(grand_total < 25 ~ \"112 Other Companies\",\r\n                                    TRUE ~ parent_company)) %>% \r\n    add_count(parent_company)\r\n\r\n#Total plastic objects in The Philippines\r\nplastics_philippines %>% \r\n  summarise(total = sum(grand_total)) -> philippines_total\r\n\r\n#Volunteers in The Philippines\r\nphilippines_volunteers <- plastics_philippines[1, 14]\r\n\r\n#Companies in The Philippines\r\nphilippines_companies <- nrow(plastics_philippines)\r\n\r\n#Plot colors  \r\nbigger <- \"midnightblue\"\r\nmiddle <- \"slateblue3\"\r\nsmall <- \"skyblue4\"\r\nother <- \"magenta4\"\r\ntext <- \"black\"\r\n\r\n#Plot  \r\nplastics_philippines %>%  \r\n    group_by(parent_company) %>%  \r\n    summarise(grand_total = sum(grand_total)) %>% \r\n    mutate(parent_company = paste0(parent_company, \"\\n(\", grand_total, \")\"),\r\n           group = case_when(grand_total > 250 ~ glue(\"{bigger}\"),\r\n                             grand_total > 100 ~ glue(\"{middle}\"),\r\n                             grand_total == 243 ~ glue(\"{other}\"),\r\n                             TRUE ~ glue(\"{small}\"))) %>% \r\n    ggplot(aes(area = grand_total, label = parent_company, fill = group)) +\r\n    geom_treemap() +\r\n    geom_treemap_text(color = \"white\", reflow = TRUE) +\r\n    scale_fill_identity() +\r\n    labs(title = \"**Worst Plastic Polluting Companies in Thailand**<br>\",\r\n         caption = \"2 Feb 2021 #TidyTuesday dataset || Joe Walderman || Inspired by @luisfreii\") +\r\n    theme(plot.margin = unit(c(2, 2, 2, 2), \"lines\"),\r\n          plot.title = element_markdown(hjust = .5, size = 14, color = text),\r\n          plot.subtitle = element_markdown(hjust = .5, color = text),\r\n          plot.caption = element_markdown(hjust = .5, color = text)\r\n          )\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-15-thailand-worst-plastic-polluters/thailand-worst-plastic-polluters_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-03-15T19:45:53-07:00",
    "input_file": "thailand-worst-plastic-polluters.utf8.md"
  },
  {
    "path": "posts/2021-03-15-solar-array-suitability/",
    "title": "Solar Array Suitability",
    "description": "GIS model designed to identify sitess on Universtiy of Richmond campus suitable for installing a 204.8 kW solar array consisting of 748 bifacial panels.",
    "author": [
      {
        "name": "Joe Walderman",
        "url": {}
      }
    ],
    "date": "2021-02-17",
    "categories": [],
    "contents": "\r\nAbstract\r\nThe purpose of our project is to analyze certain aspects of the University of Richmond campus geography to determine the most suitable locations for the implementation of additional solar panel arrays. We utilized available LIDAR data to generate a digital elevation model. From there we filtered locations using slope, elevation, aspect, and solar radiation masks. With this criteria we built a model that identified the most efficient locations for the introduction of solar panels on the Richmond campus.\r\n\r\nhide\r\nknitr::include_graphics(\"SolarPoster.pdf\")\r\n\r\n\r\n\r\nMain Takeaways\r\nWe were able to conclude from our project that the 204.8 kW solar array on the roof of the Weinstein Center for Recreation and Wellness, consisting of 749 bifacial panels covering roughly 22,000 square feet were not sited for maximum efficiency. Implementing the array just 50 feet away on the roof of the Robins Center, rathe than the adjacent recreation center would have been optimal based on our criteria and analysis. The Office of Sustainability has recognized our efforts and will use our model going forward with future solar energy projects.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-03-15T19:26:03-07:00",
    "input_file": "solar-array-suitability.utf8.md"
  },
  {
    "path": "posts/2021-01-21-welcome/",
    "title": "welcome",
    "description": "Wlcome to my blog!",
    "author": [
      {
        "name": "joe walderman",
        "url": {}
      }
    ],
    "date": "2021-01-21",
    "categories": [],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2021-02-07T22:35:33-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-09-anaerobic-digestor/",
    "title": "Achieving Waste & Emissions Reduction Goals on University of Richmond Campus",
    "description": "This post contains the final product of my senior capstone project, proposing the implementation of an anaerobic digestor on the University of Richmond campus.",
    "author": [
      {
        "name": "Joe Walderman",
        "url": {}
      }
    ],
    "date": "2017-04-20",
    "categories": [],
    "contents": "\r\nAbstract\r\nThis project proposes the installation of a small-scale anaerobic digester (biodigester). This is a reactor that breaks down biodegradable organic waste producing biogas. Food waste is considered one of the most efficient for producing biogas of typical biodigester feedstocks (Poschl, 2010). The UR Dining Hall produces 614 lbs of food waste per day to be used as feedstock, with landscaping scraps available for additional feed. The University boiler plant is capable of using biogas for heat production, making the plant a suitable destination for the digester’s waste output. The digester may allow for waste diversion and greenhouse gas (GHG) emissions reductions while also saving money on transportation and natural gas.\r\n\r\nhide\r\nknitr::include_graphics(\"digestor.pdf\")\r\n\r\n\r\n\r\nMain Takeaways\r\nBased on our analysis, the implementation of a biodigester on campus would provide a variety of benefits to the University, while also helping to achieve the University’s goals in waste and GHG emission reductions. We propose diverting pre- and post-consumer waste from HDC, along with input from landscaping, to the biodigester. Each student produces 2.0-2.6 ounces of waste per meal, times 30,000 customers a week (roughly). This equates to 3,750 pounds of postconsumer food waste per week, to be supplemented by 3,000-5,000 pounds per week of preconsumer food waste, and varied but negligible amounts of landscaping scraps. Assuming the minimum amount of operating weeks for the University in Fall and Spring semesters at 30 weeks, HDC is producing 56 tons of food waste annually, all of which could go to the digester. This would produce 1,487 MCF of biogas per year. We propose diverting the produced biogas to the steam plant on campus, to be mixed with natural gas to produce cleaner heat energy. This output would save the University $5,052.78 on natural gas and transportation costs annually.\r\nRecommended Citation\r\nWalderman, Joe and Alexa Williams. “Achieving Waste & Emissions Reduction Goals on University of Richmond Campus: The Biodigester Approach.” Poster session for Environmental Studies Senior Seminar/Geography Capstone, University of Richmond, April 20, 2017.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-03-15T19:14:26-07:00",
    "input_file": "anaerobic-digestor.utf8.md"
  }
]
